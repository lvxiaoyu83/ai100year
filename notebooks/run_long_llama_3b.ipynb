{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import LlamaTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"syzymon/long_llama_3b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"syzymon/long_llama_3b\", \n",
    "                                            torch_dtype=torch.float32, \n",
    "                                            trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input handling and generation\n",
    "LongLLaMA uses the Hugging Face interface, \n",
    "\n",
    "the long input given to the model will be split into context windows and loaded into the memory cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"My name is Julien and I like to\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids=input_ids)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_output = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_new_tokens=256,\n",
    "    num_beams=1,\n",
    "    last_context_length=1792,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    ")\n",
    "print(tokenizer.decode(generation_output[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My name is Julien and I like to describe myself with the saying: “a man, not of this world, or of this time, or of this species.” Having just been raised from near death as an alien hybrid by a secretive government organization, I decided to learn everything about it I could. I have no past, no memories beyond that night, and in many ways, I still feel like an alien to myself. There is a place I want to go. I have been traveling the world and am now in an isolated mountain town in North Carolina. For now, my only way of getting there is riding a motorcycle, and I will only get there through the help of others around me. There’s a trail I must follow. There’s a trail I must find. There’s a trail I am meant to find…\n",
    "The trailer was so creepy. I just couldn’t stop re-watching it. I knew that it was going to be a movie that would appeal to me from the first moment. It has the mystery of a story that has the ability to hook you from minute 1, to the conclusion at which you realize that not everything was as it appeared to be.\n",
    "Wow. This movie delivers.\n",
    "Now, I have to admit that I got into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(prompt):\n",
    "    # prompt = \"My name is Julien and I like to\"\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=256,\n",
    "        num_beams=1,\n",
    "        last_context_length=1792,\n",
    "        do_sample=True,\n",
    "        temperature=1.0,\n",
    "    )\n",
    "    print(tokenizer.decode(generation_output[0]))\n",
    "\n",
    "gen(\"北京是中国最大的\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<s>北京是中国最大的优秀视采国内的选择,视采会更精采性能花了过多了,以及地理位置在全校地区有太高于特金旅游的情况下,运用太高的精采可能时成竟舊凜宓,算实能低或没有作为每次视采的口氣脣优势。\n",
    "\n",
    "更能使�"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babagpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
