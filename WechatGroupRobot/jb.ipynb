{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb8083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "https://api.openai-proxy.com/v1\n"
     ]
    }
   ],
   "source": [
    "from tools import *\n",
    "from pachong2 import *\n",
    "from openai_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ef5476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.openai-proxy.com/v1\n",
      "白星花AI实验室 || 大模型时代: 知识图谱过时了吗？Griffith大学等最新《统一大型语言模型和知识图谱:路线图》 \n",
      "\n",
      "近期有一项研究详细阐述了如何将大型语言模型（LLMs）和知识图谱（KGs）结合起来，提出了一个完整的指南，告诉我们如何最好地利用它们的优势。KGs作为结构化的知识模型能够存储大量事实知识，并具有符号推理能力，而LLMs则能通过在大规模语料库上进行训练表现出色。将两者统一起来可以增强LLMs的效果并解决其缺点。研究中提到了三种统一框架：KG增强的LLMs、LLM增强的KGs以及协同作用的LLMs + KGs。文章还总结了各个框架已有工作和未来发展方向，并介绍了使用LLMs和KGs在不同领域应用时取得的成果。\n",
      "\n",
      "\n",
      "\n",
      "https://api.openai-proxy.com/v1\n",
      "InfoQ || 这将是一场灾难？37年历史的PostgreSQL数据库将进行重大架构变更 \n",
      "\n",
      "PostgreSQL是一款历史悠久的跨平台、免费和开源的数据库软件，经过几十年的发展，广泛应用于开发领域。近期，该项目团队考虑对其架构进行根本性变更，以适应现实世界中不断变化的需求。提案建议将PostgreSQL从进程模型转为线程模型，并解决由此带来的挑战。尽管存在一些争论和担忧，大部分开发者支持这种改动，并认为它有望提升系统性能和扩展性。然而，在具体实施之前仍需要进行深入研究和讨论。\n",
      "\n",
      "[来源链接](https://www.infoq.cn/article/0ZkfM2yFe3CSbzwz9IdS)\n",
      "\n",
      "\n",
      "https://api.openai-proxy.com/v1\n",
      "极客公园 || 张勇卸任、马云回归，阿里的巨变时刻 \n",
      "\n",
      "阿里巴巴宣布张勇将于9月10日卸任董事会主席兼CEO职务，专注阿里云的发展。同时，集团执行副主席蔡崇信将担任集团董事会主席，吴泳铭出任控股集团CEO。此次调整在今年3月的组织架构调整后已经预料之中，标志着阿里巴巴迎来了一个新时代。马云近期内部讲话也指出未来发展方向：回归淘宝、回归用户、回归互联网。张勇将专注于阿里云智能，并推测一年内可能上市。这次调整证明了阿里对各业务拆分上市计划加速进行。“始终以用户为中心”的旗号,其实是马化腾给自家产品做广告用的,被滥炮金字塔模型持有者逐渐变成屏幕背后的交付手。\n",
      "\n",
      "\n",
      "\n",
      "https://api.openai-proxy.com/v1\n",
      "甲子光年 || 腾讯大模型交卷：不追求参数，走实用路线｜甲子光年 \n",
      "\n",
      "腾讯云近日发布了行业大模型，而非对话机器人。它们将重点放在与腾讯云结合的行业大模型上，并分享了整套系统架构。与其他云厂商相似，腾讯云也采用MaaS（Model-as-a-Service）模式，在不同行业中与客户合作开发垂类大模型解决方案。该平台提供超过50个解决方案，服务金融、文旅、政务、传媒和教育等多个领域。\n",
      "同时，汤道生表示通用大语言模型应对产业场景落地的局限性较高，并强调了针对性精密化的行业大模型的需求。吴运声介绍了全新升级后的行业大模型产品架构，称其为“低成本落地”、“最优解”。除此之外，他还谈到自研算法能力和安全能力。\n",
      "\n",
      "此次发布会展示了一些具体应用情景：\n",
      "1. 文旅领域：机器人提供详细的旅游攻略并自动预定酒店和车票；\n",
      "2. 金融领域：OCR 大模型帮助实现高效创造智能化服务；\n",
      "3. 聚焦电子商务领域的AI代码助手支持多种编程语言和主流开发框架。\n",
      "\n",
      "当前，大模型技术已成为云计算服务商竞争的新焦点。腾讯云发布行业大模型是为在激烈的市场竞争中占据优势。虽然腾讯云市场份额有所下降，但其战略转变和实用路线使其能够更好地解决客户问题并推动落地应用。最后，文章表示腾讯在这个领域的进一步战略和产品令人期待。\n",
      "\n",
      "\n",
      "https://api.openai-proxy.com/v1\n",
      "算法进阶 || 看了100多篇顶刊顶会后，我发现··· \n",
      "\n",
      "如今，科研人员越来越重视论文中插图的质量。Springer Nature将插图称为\"Artwork\"，国内外的团队会雇请专门的美工来润色图片。很多科研人反映，在写论文时绘制插图是一项头疼的任务。因此，有一位长期担任计算机顶级会议审稿人的中科院博士后邀请大家参加在线直播课程，教授关于科研论文图像与视频制作技巧。通过这个课程可以学习到处理颜色、排版和使用不同类型的图表等要点，帮助提高SCI论文插图的水准。\n",
      "\n",
      "\n",
      "\n",
      "https://api.openai-proxy.com/v1\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for default-gpt-3.5-turbo-16k in organization org-l8SqtXKkMausL4w3hEEB0dc4 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m     f_ctt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# open_dingyuehao_2()\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mgooo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mgooo\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m ulist:\n\u001b[0;32m     10\u001b[0m     hao, title, desc, ctt \u001b[38;5;241m=\u001b[39m get_wechat_artile_content(url)\n\u001b[1;32m---> 11\u001b[0m     _, \u001b[38;5;28mabs\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcall_with_sys\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctt\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m || \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (hao, title))\u001b[38;5;66;03m#desc\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mabs\u001b[39m)\n",
      "File \u001b[1;32mD:\\code\\ai100year\\WechatGroupRobot\\openai_tools.py:23\u001b[0m, in \u001b[0;36mcall_with_sys\u001b[1;34m(sys_content, user_content_text)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_with_sys\u001b[39m(sys_content, user_content_text):\n\u001b[0;32m     19\u001b[0m   \u001b[38;5;66;03m# print(openai.api_base)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m   msg \u001b[38;5;241m=\u001b[39m [  \n\u001b[0;32m     21\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: sys_content},\n\u001b[0;32m     22\u001b[0m           {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: sys_content \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39muser_content_text}  ]\n\u001b[1;32m---> 23\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-16k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m   \u001b[38;5;66;03m# print(response.id,\":\\n\",response.choices[0].message.content)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mid, response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo-16k in organization org-l8SqtXKkMausL4w3hEEB0dc4 on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
     ]
    }
   ],
   "source": [
    "\n",
    "def gooo():\n",
    "    sys_prompt = \"跟据用户给出的文字提取100字的摘要：\"\n",
    "    ulist = wechat_article_list(5, 1)\n",
    "    now = now_str()\n",
    "    \n",
    "    f_meta = open(\"_wechat_url\" + \"_\" + now + \".md\", \"w\", encoding=\"utf-8\")\n",
    "    f_ctt = open(\"_wechat_content\" + \"_\" + now + \".txt\", \"w\", encoding=\"utf-8\")\n",
    "    \n",
    "    for url in ulist:\n",
    "        hao, title, desc, ctt = get_wechat_artile_content(url)\n",
    "        _, abs = call_with_sys(sys_prompt, ctt) \n",
    "\n",
    "        print(\"%s || %s \\n\" % (hao, title))#desc\n",
    "        print(abs)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        f_meta.write(\"### %s || %s \\n\\n %s\\n\\n %s\\n<hr/>\\n\\n\\n\\n\\n\" % (hao, title, abs, url))\n",
    "        f_meta.flush()\n",
    "        \n",
    "        f_ctt.write(\"%s : %s : %s: %s\\n\" % (hao, title, desc, url))\n",
    "        f_ctt.write(\"%s\\n\\n\\n\\n\\n\\n\" % ctt)\n",
    "        f_ctt.flush()\n",
    "        \n",
    "        time.sleep(0.8)\n",
    "    \n",
    "    f_meta.close()\n",
    "    f_ctt.close()\n",
    "# open_dingyuehao_2()\n",
    "gooo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d44c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
